{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0155264",
   "metadata": {},
   "source": [
    "# Task 3 - Train on NEU train with the NSL after Histogram Equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e84e37ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06074068",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_crazing_dir = os.path.join('data/NEU-DET-HIS/train/images/crazing')\n",
    "train_inclusion_dir = os.path.join('data/NEU-DET-HIS/train/images/inclusion')\n",
    "train_patches_dir = os.path.join('data/NEU-DET-HIS/train/images/patches')\n",
    "train_pitted_surface_dir = os.path.join('data/NEU-DET-HIS/train/images/pitted_surface')\n",
    "train_rolledin_scale_dir = os.path.join('data/NEU-DET-HIS/train/images/rolled-in_scale')\n",
    "train_scratches_dir = os.path.join('data/NEU-DET-HIS/train/images/scratches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3dd9bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_crazing_names = os.listdir(train_crazing_dir)\n",
    "train_inclusion_names = os.listdir(train_inclusion_dir)\n",
    "train_patches_names = os.listdir(train_patches_dir)\n",
    "train_pitted_surface_names = os.listdir(train_pitted_surface_dir)\n",
    "train_rolledin_scale_names = os.listdir(train_rolledin_scale_dir)\n",
    "train_scratches_names = os.listdir(train_scratches_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "297b9075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training crazing images: 241\n",
      "total training inclusion images: 241\n",
      "total training patches images: 241\n",
      "total training pitted_surface images: 241\n",
      "total training rolled_in_scale images: 241\n",
      "total training scratches images: 240\n"
     ]
    }
   ],
   "source": [
    "print('total training crazing images:', len(train_crazing_names))\n",
    "print('total training inclusion images:', len(train_inclusion_names))\n",
    "print('total training patches images:', len(train_patches_names))\n",
    "print('total training pitted_surface images:', len(train_pitted_surface_names))\n",
    "print('total training rolled_in_scale images:', len(train_rolledin_scale_names))\n",
    "print('total training scratches images:', len(train_scratches_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0644e4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c991740",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "                                    # First Convolution\n",
    "                                    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(224, 224, 3)),\n",
    "                                    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "                                    # Second Convolution\n",
    "                                    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "                                    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "                                    # Third Convolution\n",
    "                                    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "                                    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "                                    tf.keras.layers.Flatten(),\n",
    "                                    tf.keras.layers.Dense(512, activation='relu'),\n",
    "                                    tf.keras.layers.Dense(512, activation='relu'),\n",
    "                                    tf.keras.layers.Dense(6, activation='softmax'),])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfc51e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 52, 52, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 26, 26, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 21632)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               11076096  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 6)                 3078      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,361,222\n",
      "Trainable params: 11,361,222\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a6253a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neural_structured_learning as nsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3828e207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the model with adversarial regularization.\n",
    "adv_config = nsl.configs.make_adv_reg_config(multiplier=0.2, adv_step_size=0.05)\n",
    "adv_model = nsl.keras.AdversarialRegularization(model, adv_config=adv_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d061db52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile, train, and evaluate.\n",
    "adv_model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7641dcd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1440 images belonging to 6 classes.\n",
      "Found 360 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "\n",
    "# Rescaling images\n",
    "data_generator = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "    directory = 'data/NEU-DET-HIS/train/images/',\n",
    "    target_size = (224, 224),\n",
    "    batch_size = 60,\n",
    "    class_mode = 'categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    directory = 'data/NEU-DET-HIS/validation/images/',\n",
    "    target_size = (224, 224),\n",
    "    batch_size = 60,\n",
    "    class_mode = 'categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ec6e311",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = next(train_generator)\n",
    "y_train = np.argmax(y_train, axis=1)\n",
    "X_test, y_test = next(validation_generator)\n",
    "y_test = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1ab86c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91800\\anaconda3\\envs\\MTP\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:264: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.int64\n",
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Cannot perturb features dict_keys(['label'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/2 [==============>...............] - ETA: 4s - loss: 2.1484 - sparse_categorical_crossentropy: 1.7893 - sparse_categorical_accuracy: 0.1562 - scaled_adversarial_loss: 0.3591WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 7s 3s/step - loss: 2.9772 - sparse_categorical_crossentropy: 2.4798 - sparse_categorical_accuracy: 0.1333 - scaled_adversarial_loss: 0.4974\n",
      "Epoch 2/5\n",
      "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/2 [==============>...............] - ETA: 3s - loss: 2.2121 - sparse_categorical_crossentropy: 1.8424 - sparse_categorical_accuracy: 0.2500 - scaled_adversarial_loss: 0.3697WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 7s 3s/step - loss: 2.3113 - sparse_categorical_crossentropy: 1.9251 - sparse_categorical_accuracy: 0.1500 - scaled_adversarial_loss: 0.3861\n",
      "Epoch 3/5\n",
      "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the watched tensor must be floating (e.g. tf.float32), got tf.int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/2 [==============>...............] - ETA: 3s - loss: 2.1571 - sparse_categorical_crossentropy: 1.7969 - sparse_categorical_accuracy: 0.2812 - scaled_adversarial_loss: 0.3602WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 7s 3s/step - loss: 2.1737 - sparse_categorical_crossentropy: 1.8107 - sparse_categorical_accuracy: 0.2667 - scaled_adversarial_loss: 0.3630\n",
      "Epoch 4/5\n",
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/2 [==============>...............] - ETA: 3s - loss: 2.0676 - sparse_categorical_crossentropy: 1.7224 - sparse_categorical_accuracy: 0.4062 - scaled_adversarial_loss: 0.3452WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 7s 3s/step - loss: 2.0832 - sparse_categorical_crossentropy: 1.7353 - sparse_categorical_accuracy: 0.2667 - scaled_adversarial_loss: 0.3479\n",
      "Epoch 5/5\n",
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/2 [==============>...............] - ETA: 3s - loss: 2.0253 - sparse_categorical_crossentropy: 1.6870 - sparse_categorical_accuracy: 0.6562 - scaled_adversarial_loss: 0.3383WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 7s 3s/step - loss: 2.0485 - sparse_categorical_crossentropy: 1.7063 - sparse_categorical_accuracy: 0.3667 - scaled_adversarial_loss: 0.3422\n"
     ]
    }
   ],
   "source": [
    "history = adv_model.fit({'feature': X_train, 'label': y_train}, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58db9acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [2.977160930633545,\n",
       "  2.311278820037842,\n",
       "  2.173699378967285,\n",
       "  2.08317232131958,\n",
       "  2.0484752655029297],\n",
       " 'sparse_categorical_crossentropy': [2.479759454727173,\n",
       "  1.9251289367675781,\n",
       "  1.810719609260559,\n",
       "  1.7353184223175049,\n",
       "  1.7063243389129639],\n",
       " 'sparse_categorical_accuracy': [0.13333334028720856,\n",
       "  0.15000000596046448,\n",
       "  0.2666666805744171,\n",
       "  0.2666666805744171,\n",
       "  0.36666667461395264],\n",
       " 'scaled_adversarial_loss': [0.49740147590637207,\n",
       "  0.38614988327026367,\n",
       "  0.3629799485206604,\n",
       "  0.3478539288043976,\n",
       "  0.3421509265899658]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50820c6",
   "metadata": {},
   "source": [
    "## Test on NEU test, and whole ENEU after Histogram Equalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afa03cdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/2 [==============>...............] - ETA: 1s - loss: 2.1030 - sparse_categorical_crossentropy: 1.7515 - sparse_categorical_accuracy: 0.1250 - scaled_adversarial_loss: 0.3514WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 2s/step - loss: 2.0915 - sparse_categorical_crossentropy: 1.7420 - sparse_categorical_accuracy: 0.2000 - scaled_adversarial_loss: 0.3495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.0914511680603027,\n",
       " 1.741976261138916,\n",
       " 0.20000000298023224,\n",
       " 0.3494751751422882]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_model.evaluate({'feature': X_test, 'label': y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a36fe1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11160 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator_ENEU = data_generator.flow_from_directory(\n",
    "    directory = 'images_preprocessed\\images_histeq_resize\\ENEU',\n",
    "    target_size = (1,224, 224),\n",
    "    batch_size = 60,\n",
    "    class_mode = 'categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4082201",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_ENEU, y_test_ENEU = next(validation_generator_ENEU)\n",
    "X_test_ENEU = np.argmax(X_test_ENEU, axis=1)\n",
    "y_test_ENEU = np.argmax(y_test_ENEU, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b7e5282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/2 [==============>...............] - ETA: 1s - loss: 2.1620 - sparse_categorical_crossentropy: 1.8016 - sparse_categorical_accuracy: 0.1562 - scaled_adversarial_loss: 0.3603WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The dtype of the source tensor must be floating (e.g. tf.float32) when calling GradientTape.gradient, got tf.int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 3s 2s/step - loss: 2.1536 - sparse_categorical_crossentropy: 1.7946 - sparse_categorical_accuracy: 0.1833 - scaled_adversarial_loss: 0.3589\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.1535797119140625,\n",
       " 1.7946497201919556,\n",
       " 0.18333333730697632,\n",
       " 0.35892993211746216]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adv_model.evaluate({'feature': X_test_ENEU, 'label': y_test_ENEU})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7546d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
