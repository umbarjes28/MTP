{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c63f102d",
   "metadata": {},
   "source": [
    "# Feature extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1b6e6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from helper.classification_tools import CustomLabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "984f24b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 10 filenames: ['pitted_surface_286.jpg', 'rolled-in_scale_126.jpg', 'scratches_295.jpg', 'inclusion_20.jpg', 'crazing_79.jpg', 'crazing_40.jpg', 'rolled-in_scale_214.jpg', 'inclusion_180.jpg', 'crazing_274.jpg', 'rolled-in_scale_108.jpg']\n"
     ]
    }
   ],
   "source": [
    "img_root = Path('NEU-DET-MIX-HIS')  # directory where images are stored.\n",
    "assert img_root.is_dir() # make sure directory exists and is properly found\n",
    "files = sorted(img_root.glob(\"*.jpg\"))  # returns a list of all of the images in the directory, sorted by filename.\n",
    "\n",
    "## Shuffle the filenames so they appear randomly in the dataset. \n",
    "rs = np.random.RandomState(seed=749976)\n",
    "rs.shuffle(files)\n",
    "\n",
    "assert len(files) == 1800  # make sure all files are found.\n",
    "print('first 10 filenames: {}'.format([x.name for x in files[:10]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6be99417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 10 labels: ['pitted', 'rolled-in', 'scratches', 'inclusion', 'crazing', 'crazing', 'rolled-in', 'inclusion', 'crazing', 'rolled-in']\n"
     ]
    }
   ],
   "source": [
    "def extract_labels(f): return [x.stem.split('_')[0] for x in f]\n",
    "labels = extract_labels(files)\n",
    "print('first 10 labels: {}'.format(labels[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2eb3b116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label encodings: {'crazing': 0, 'inclusion': 1, 'patches': 2, 'pitted': 3, 'rolled-in': 4, 'scratches': 5}\n",
      "first 10 integer labels: [3 4 5 1 0 0 4 1 0 4]\n",
      "first 10 string labels: ['pitted' 'rolled-in' 'scratches' 'inclusion' 'crazing' 'crazing'\n",
      " 'rolled-in' 'inclusion' 'crazing' 'rolled-in']\n"
     ]
    }
   ],
   "source": [
    "le = CustomLabelEncoder()\n",
    "le.fit(labels, sorter=lambda x: x.upper())\n",
    "\n",
    "labels_int = le.transform(labels[:10])\n",
    "labels_str = le.inverse_transform(labels_int)\n",
    "\n",
    "# save the label encoder so it can be used throughout the rest of this study\n",
    "with open(Path('models','label_encoder.pickle'), 'wb') as f:\n",
    "    pickle.dump(le, f)\n",
    "\n",
    "print('label encodings: {}'.format(le.mapper))\n",
    "print('first 10 integer labels: {}'.format(labels_int))\n",
    "print('first 10 string labels: {}'.format(labels_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d728274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(paths):\n",
    "    \"\"\"\n",
    "    Loads images in the correct format for use with the Keras VGG16 model\n",
    "    \n",
    "    Images are loaded as PIL image objects, converted to numpy array, and then formatted\n",
    "    with the appropriate VGG16.preprocess_input() function. Note that this only changes\n",
    "    how the images are represented, it does not change the actual visual properties of the\n",
    "    images like preprocessing did before.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    paths: list(Path)\n",
    "        list of Paths to each file where the image is stored. Note that the images should \n",
    "        have the same height, width in pixels so they can be stored in one array.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    images: ndarray\n",
    "        n_images x r x c x 3 array of pixel values that is compatible with the Keras model.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    images = [image.load_img(file) for file in paths] # load images\n",
    "    # convert images to an array with shape consistent for the vgg16 input\n",
    "    images = np.asarray([image.img_to_array(img) for img in images]) \n",
    "    # normalizes the pixel values to match the imagenet format (and therefore the pre-trained weights)\n",
    "    images = preprocess_input(images) \n",
    "    \n",
    "    return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41d8cc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "images = load_images(files)\n",
    "assert len(images) == 1800\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022d9971",
   "metadata": {},
   "source": [
    "## Feature extraction\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f2c3df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "vgg16_path = Path('models','VGG16.h5')\n",
    "if not vgg16_path.is_file():\n",
    "    vgg16 = keras.applications.VGG16(include_top=True,  # include fully connected layers\n",
    "                                     weights='imagenet') # use pre-trained model\n",
    "    vgg16.save(vgg16_path) # save model so we don't have to download it everytime\n",
    "    \n",
    "else:   \n",
    "    vgg16 = keras.models.load_model(vgg16_path) # use saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acda502b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1000)              4097000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ef2cd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_extractor(model=vgg16, layer='fc1'):\n",
    "    \"\"\"\n",
    "    returns a model that will extract the outputs of *layer* from *model*.\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    model: keras model\n",
    "        full model from which intermediate layer will be extracted\n",
    "    layer: string\n",
    "        name of layer from which to extract outputs\n",
    "    \n",
    "    Returns\n",
    "    -------------\n",
    "    new_model: keras model\n",
    "        feature extractor model which takes the same inputs as *model* and returns the outputs\n",
    "        of the intermediate layer specified by *layer* by calling new_model.predict(inputs)\n",
    "    \"\"\"\n",
    "    assert layer in [x.name for x in model.layers]  # make sure the layer exists\n",
    "\n",
    "    new_model = keras.Model(inputs = vgg16.input, outputs=[vgg16.get_layer(layer).output])\n",
    "    \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54813f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 314s 5s/step\n",
      "(1800, 4096)\n"
     ]
    }
   ],
   "source": [
    "fc1_extractor = layer_extractor()\n",
    "fc1 = fc1_extractor.predict(images, verbose=True)\n",
    "\n",
    "# save results\n",
    "results = {'filename' : files,\n",
    "           'features': fc1,\n",
    "          'labels': labels,\n",
    "           'layer_name': 'fc1'\n",
    "          }\n",
    "\n",
    "feature_dir = Path('data','features')\n",
    "os.makedirs(feature_dir, exist_ok=True)\n",
    "with open(feature_dir / 'VGG16_fc1_features_std.pickle', 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "\n",
    "print(fc1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4f99054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'block3_conv2' in [x.name for x in vgg16.layers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "743f8c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting features: fc2\n",
      "57/57 [==============================] - 348s 6s/step\n",
      "extracting features: block5_pool\n",
      "57/57 [==============================] - 327s 6s/step\n",
      "extracting features: block5_conv3\n",
      "57/57 [==============================] - 327s 6s/step\n"
     ]
    }
   ],
   "source": [
    "for layer in ['fc2', 'block5_pool', 'block5_conv3']:\n",
    "    print(f'extracting features: {layer}')\n",
    "    extractor = layer_extractor(layer=layer)  # model to extract features for each layer\n",
    "    features = extractor.predict(images, verbose=True)  # features extracted by model\n",
    "    # save the results using the same format as before\n",
    "    results = {'filename': files,\n",
    "              'features': features,\n",
    "              'labels': labels,\n",
    "              'layer_name': layer}\n",
    "    with open(feature_dir / 'VGG16_{}_features.pickle'.format(layer), 'wb') as f:\n",
    "        pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437f3fab",
   "metadata": {},
   "source": [
    "## FC1 features without histogram equalization\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5727b2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 5 filenames and labels\n",
      "['pitted_surface_291.jpg', 'pitted_surface_116.jpg', 'crazing_136.jpg', 'crazing_232.jpg', 'pitted_surface_188.jpg']\n",
      "['pitted', 'pitted', 'crazing', 'crazing', 'pitted']\n"
     ]
    }
   ],
   "source": [
    "img_root_nohisteq = Path('images_preprocessed','images_resize')\n",
    "assert img_root_nohisteq.is_dir()\n",
    "files_noh = sorted(img_root_nohisteq.glob('*'))\n",
    "rs = np.random.RandomState(seed=3626210179)\n",
    "rs.shuffle(files_noh)\n",
    "labels_noh = extract_labels(files_noh)\n",
    "assert len(files_noh) == 1800\n",
    "print('first 5 filenames and labels')\n",
    "print([x.name for x in files_noh[:5]])\n",
    "print(labels_noh[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75978193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 407s 6s/step\n"
     ]
    }
   ],
   "source": [
    "# follow the same process described above to load images, convert to array, and format for vgg16\n",
    "images_noh = load_images(files_noh)\n",
    "fc1_noh = fc1_extractor.predict(images_noh, verbose=True)\n",
    "\n",
    "results = {'filename': files_noh,\n",
    "          'features': fc1_noh,\n",
    "          'labels': labels_noh,\n",
    "          'layer_name': 'fc1 no_histeq'}\n",
    "with open(feature_dir / 'VGG16_fc1_features_NoHistEQ.pickle', 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25af09fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
